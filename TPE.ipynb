{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9da476",
   "metadata": {},
   "source": [
    "# Scikitlearn ( Regression linéaire, SGD, regression logistique et Principal Component Analysis) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f3c72",
   "metadata": {},
   "source": [
    "# I - Regression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce5eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0476a798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-08-19</td>\n",
       "      <td>49.676899</td>\n",
       "      <td>51.693783</td>\n",
       "      <td>47.669952</td>\n",
       "      <td>49.845802</td>\n",
       "      <td>49.845802</td>\n",
       "      <td>44994500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-20</td>\n",
       "      <td>50.178635</td>\n",
       "      <td>54.187561</td>\n",
       "      <td>49.925285</td>\n",
       "      <td>53.805050</td>\n",
       "      <td>53.805050</td>\n",
       "      <td>23005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-23</td>\n",
       "      <td>55.017166</td>\n",
       "      <td>56.373344</td>\n",
       "      <td>54.172661</td>\n",
       "      <td>54.346527</td>\n",
       "      <td>54.346527</td>\n",
       "      <td>18393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-24</td>\n",
       "      <td>55.260582</td>\n",
       "      <td>55.439419</td>\n",
       "      <td>51.450363</td>\n",
       "      <td>52.096165</td>\n",
       "      <td>52.096165</td>\n",
       "      <td>15361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-25</td>\n",
       "      <td>52.140873</td>\n",
       "      <td>53.651051</td>\n",
       "      <td>51.604362</td>\n",
       "      <td>52.657513</td>\n",
       "      <td>52.657513</td>\n",
       "      <td>9257400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2004-08-19  49.676899  51.693783  47.669952  49.845802  49.845802  44994500\n",
       "1  2004-08-20  50.178635  54.187561  49.925285  53.805050  53.805050  23005800\n",
       "2  2004-08-23  55.017166  56.373344  54.172661  54.346527  54.346527  18393200\n",
       "3  2004-08-24  55.260582  55.439419  51.450363  52.096165  52.096165  15361800\n",
       "4  2004-08-25  52.140873  53.651051  51.604362  52.657513  52.657513   9257400"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/hamza/Téléchargements/stocks.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a366c",
   "metadata": {},
   "source": [
    "# II - A - Regression Logistique (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ab46b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a01bc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('/home/hamza/Téléchargements/iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92dcfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_standard(data):\n",
    "    dmean=np.mean(data, axis=0)\n",
    "    dstd=np.std(data, axis=0)\n",
    "    data_scaled=(data-dmean)/dstd\n",
    "    return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f0de0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, train_percent):\n",
    "    np.random.seed(2)\n",
    "    perm=np.random.permutation(df.index)\n",
    "    n=len(df)\n",
    "\n",
    "    train_index=int(train_percent*n)\n",
    "    train=df.iloc[perm[:train_index]]\n",
    "    test=df.iloc[perm[train_index:]]\n",
    "\n",
    "    x_train=train.iloc[:, :-1]\n",
    "    y_train=train.iloc[:, -1]\n",
    "\n",
    "    x_test=test.iloc[:, :-1]\n",
    "    y_test= test.iloc[:,-1]\n",
    "\n",
    "    return x_train.values, x_test.values, y_train.values, y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d4ffb3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 6), (2982, 6), (331,), (2982,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=split_data(data,0.10)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8cdbcf",
   "metadata": {},
   "source": [
    "# II - B - Logistic Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2daff80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class logistic_regression:\n",
    "    def _init_(self, epoch=100, threhold=0.5, tolerance=1e-10, lr=0.0001):\n",
    "        self.epochs=epochs\n",
    "        self.threshold=threshold\n",
    "        self.lr=lr\n",
    "        self.tolerance=tolerance\n",
    "        self.theta= None\n",
    "        \n",
    "        self.cost_history=[]\n",
    "        self.cost_history_test=[]\n",
    "        \n",
    "    def add_ones(self, x):\n",
    "        x_new=np.hstack([np.ones((x.shape[0],1)),x])\n",
    "        return x_new\n",
    "    def sigmoid(self, x, theta):\n",
    "        h= x@self.theta\n",
    "        return 1/(1+np.exp(-h))\n",
    "    def cross_entropy(self,x, y_true):\n",
    "        n=len(x) #longueur des features\n",
    "        y_pred=self.sigmoid(x,self.theta)\n",
    "        cost=-((y_true.T@np.log(y_pred))+(1-y_true.T)@np.log(1-y_pred))/n\n",
    "        return Cost[0]\n",
    "    def fit(self, x,y):\n",
    "        x=self.add_ones(x)\n",
    "        y=y.reshape(-1,1)\n",
    "        self.theta=np.zeros((x.shape[1], 1)) #initialisation de theta avec vecteur zeros\n",
    "        current_iter=1\n",
    "        norm=1\n",
    "        \n",
    "        while (norm>= self.tolerance and current_iter< self.epochs):\n",
    "            theta_old=self.theta.copy() #grader l'ancienne valeur de theta\n",
    "            \n",
    "            ##faire une prediction\n",
    "            y_pred=self.sigmoid(x, self.theta)\n",
    "            \n",
    "            #gradien\n",
    "            grad=x.T@((y.reshape(-1,1)))\n",
    "            grad=grad.reshape(-1,1) #on le fait si besoin puisque que nous le faisons from scratch sans connaitre les dimensions encore \n",
    "            \n",
    "            #upgrade rules\n",
    "            theta_new=theta_old-self.lr*grad\n",
    "            self.theta=theta_new\n",
    "            \n",
    "            #calculer les erreurs d'entrainements et de test\n",
    "            \n",
    "            self.cost_history.append(self.cross_entropy(x,y))\n",
    "            self.cost_history_test.append(self.cross_entropy(self.add_ones(x_test), y_test))\n",
    "            \n",
    "            #critères de convenance\n",
    "            if current_iter%100==0:\n",
    "                print(f'cost for{current_iter} iteration :{self.cross_entropy(x,y)}')\n",
    "            norm=np.linalg.norm(theta_old-self.theta)\n",
    "            current_iter=+1\n",
    "            #La sortie de cette fonction donnera des probabilités comme valeurs\n",
    "    def predict_proba(self,x):\n",
    "        x=self.add_ones(x)\n",
    "        y_pred=self.sigmoid(x, self, theta)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self,x):\n",
    "        proba=self.predict_proba(x)\n",
    "        result=[1 if i>self.threshold else 0 for i in proba] #convertir les probabilités en 0 et 1\n",
    "        return np.array(result)\n",
    "    def plot(self):\n",
    "        pt.figure(figsize=(10,6))\n",
    "        plt.plot(self.cost_history, label='Train Loss')\n",
    "        plt.plot(self.cost_history_test, label='Test Loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.style.use('ggplot')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dda6aa12",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logistic_regression() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#create a model by instanciating class logistic regression\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mlogistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0000019\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: logistic_regression() takes no arguments"
     ]
    }
   ],
   "source": [
    "#create a model by instanciating class logistic regression\n",
    "model=logistic_regression(epochs=1000, lr=0.0000019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45978927",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logistic_regression.fit() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0000019\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: logistic_regression.fit() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(epochs=1000, lr=0.0000019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98889804",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Test the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a2a7b",
   "metadata": {},
   "source": [
    "# III - Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4b92bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0838b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPCA():\n",
    "    from sklearn .decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(data)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32a4d41b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (137526808.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[119], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    print( pca.explained_variance_ratio_\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "pca = doPCA()\n",
    "print( pca.explained_variance_ratio_\n",
    "first_pc=pca.components_[0]\n",
    "second_pc=pca.components_[1])\n",
    "\n",
    "transformed_data = pca.transformed(data)\n",
    "for ii, jj in zip(transformed_data, data):\n",
    "    plt.scatter( first_pc[0]*ii[0], first_pc[1]*ii[0], color=\"r\")\n",
    "    plt.scatter( second_pc[0]*ii[1], second_pc[1]*ii[1], color=\"c\")\n",
    "    plt.scatter( jj[0],jj[1], color=\"b\")\n",
    "plt.xlabel(\"bonus\")\n",
    "plt.ylabel(\"long-term incentive\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565b1cc",
   "metadata": {},
   "source": [
    "# IV - Fonction train SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe748c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e070d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_regression(X, y, alpha=0.01, nb_iter=1000):\n",
    "    # Initialisation des poids theta\n",
    "    theta = np.random.random(X.shape[1])\n",
    "    \n",
    "    # Boucle d'entraînement\n",
    "    for i in range(nb_iter):\n",
    "        # Sélectionner un exemple d'entraînement aléatoire\n",
    "        rand_idx = np.random.randint(X.shape[0])\n",
    "        x_i = X[rand_idx]\n",
    "        y_i = y[rand_idx]\n",
    "        \n",
    "        # Calculer la prédiction h(x)\n",
    "        h_x = np.dot(theta, x_i)\n",
    "        \n",
    "        # Calculer l'erreur de prédiction\n",
    "        err = h_x - y_i\n",
    "        \n",
    "        # Mettre à jour les poids theta\n",
    "        theta = theta - alpha * err * x_i\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c36fcf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'erreur de prédiction moyenne est :  0.010303432872266483\n"
     ]
    }
   ],
   "source": [
    "# Générer un ensemble de données pour le test\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Entraîner un modèle de régression linéaire avec la fonction sgd_regression\n",
    "theta = sgd_regression(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = np.dot(X_test, theta)\n",
    "\n",
    "# Calculer l'erreur de prédiction moyenne\n",
    "mse = np.mean((y_pred - y_test) ** 2)\n",
    "print(\"L'erreur de prédiction moyenne est : \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d75162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
